#!/usr/bin/env python3
"""
Auto Split Large Files - Sistema de DivisiÃ³n AutomÃ¡tica de Archivos Grandes
Divide automÃ¡ticamente archivos markdown grandes en archivos mÃ¡s manejables
"""

import os
import re
import json
import argparse
from datetime import datetime
from pathlib import Path

class AutoSplitLargeFiles:
    def __init__(self, root_path=".", max_size=50000, max_lines=2000):
        self.root_path = root_path
        self.max_size = max_size
        self.max_lines = max_lines
        self.split_results = {
            "timestamp": datetime.now().isoformat(),
            "files_processed": [],
            "files_created": [],
            "total_original_size": 0,
            "total_new_size": 0,
            "reduction_percentage": 0
        }
    
    def analyze_file_structure(self, file_path):
        """Analiza la estructura de un archivo para determinar la mejor forma de dividirlo"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            lines = content.split('\n')
            total_lines = len(lines)
            total_size = len(content)
            
            if total_size < self.max_size and total_lines < self.max_lines:
                return None
            
            # Detectar secciones por headers
            sections = self.detect_sections(lines)
            
            # Detectar bloques de cÃ³digo
            code_blocks = self.detect_code_blocks(content)
            
            # Detectar listas largas
            long_lists = self.detect_long_lists(lines)
            
            # Detectar tablas grandes
            large_tables = self.detect_large_tables(content)
            
            analysis = {
                "file_path": file_path,
                "total_size": total_size,
                "total_lines": total_lines,
                "sections": sections,
                "code_blocks": code_blocks,
                "long_lists": long_lists,
                "large_tables": large_tables,
                "split_strategy": self.determine_split_strategy(sections, code_blocks, long_lists, large_tables)
            }
            
            return analysis
            
        except Exception as e:
            print(f"Error analizando {file_path}: {e}")
            return None
    
    def detect_sections(self, lines):
        """Detecta secciones basadas en headers markdown"""
        sections = []
        current_section = {
            "title": "Inicio",
            "level": 0,
            "start_line": 0,
            "end_line": 0,
            "content": "",
            "size": 0
        }
        
        for i, line in enumerate(lines):
            # Detectar headers
            header_match = re.match(r'^(#{1,6})\s+(.+)$', line)
            
            if header_match:
                # Guardar secciÃ³n anterior
                if current_section["content"]:
                    current_section["end_line"] = i - 1
                    current_section["size"] = len(current_section["content"])
                    sections.append(current_section.copy())
                
                # Iniciar nueva secciÃ³n
                level = len(header_match.group(1))
                title = header_match.group(2).strip()
                
                current_section = {
                    "title": title,
                    "level": level,
                    "start_line": i,
                    "end_line": i,
                    "content": line + '\n',
                    "size": len(line)
                }
            else:
                current_section["content"] += line + '\n'
                current_section["size"] += len(line) + 1
        
        # Agregar Ãºltima secciÃ³n
        if current_section["content"]:
            current_section["end_line"] = len(lines) - 1
            sections.append(current_section)
        
        return sections
    
    def detect_code_blocks(self, content):
        """Detecta bloques de cÃ³digo en el contenido"""
        code_blocks = []
        pattern = r'```(\w+)?\n(.*?)\n```'
        
        for match in re.finditer(pattern, content, re.DOTALL):
            language = match.group(1) or 'text'
            code = match.group(2)
            
            code_blocks.append({
                "language": language,
                "content": code,
                "start": match.start(),
                "end": match.end(),
                "size": len(code)
            })
        
        return code_blocks
    
    def detect_long_lists(self, lines):
        """Detecta listas largas en el contenido"""
        long_lists = []
        current_list = []
        in_list = False
        
        for i, line in enumerate(lines):
            # Detectar inicio de lista
            if re.match(r'^\s*[-*+]\s+', line) or re.match(r'^\s*\d+\.\s+', line):
                if not in_list:
                    in_list = True
                    current_list = [i]
                else:
                    current_list.append(i)
            else:
                if in_list and len(current_list) > 10:  # Lista larga
                    long_lists.append({
                        "start_line": current_list[0],
                        "end_line": current_list[-1],
                        "length": len(current_list),
                        "content": '\n'.join(lines[current_list[0]:current_list[-1]+1])
                    })
                in_list = False
                current_list = []
        
        return long_lists
    
    def detect_large_tables(self, content):
        """Detecta tablas grandes en el contenido"""
        large_tables = []
        lines = content.split('\n')
        
        for i, line in enumerate(lines):
            if '|' in line and line.count('|') > 3:  # Posible tabla
                table_lines = []
                j = i
                
                # Recopilar lÃ­neas de la tabla
                while j < len(lines) and '|' in lines[j]:
                    table_lines.append(lines[j])
                    j += 1
                
                if len(table_lines) > 10:  # Tabla grande
                    large_tables.append({
                        "start_line": i,
                        "end_line": j - 1,
                        "rows": len(table_lines),
                        "content": '\n'.join(table_lines)
                    })
        
        return large_tables
    
    def determine_split_strategy(self, sections, code_blocks, long_lists, large_tables):
        """Determina la mejor estrategia para dividir el archivo"""
        strategies = []
        
        # Estrategia por secciones
        if len(sections) > 5:
            strategies.append({
                "type": "sections",
                "priority": "high",
                "description": f"Dividir por {len(sections)} secciones",
                "method": "split_by_sections"
            })
        
        # Estrategia por bloques de cÃ³digo
        if len(code_blocks) > 3:
            strategies.append({
                "type": "code_blocks",
                "priority": "medium",
                "description": f"Extraer {len(code_blocks)} bloques de cÃ³digo",
                "method": "extract_code_blocks"
            })
        
        # Estrategia por listas largas
        if len(long_lists) > 2:
            strategies.append({
                "type": "long_lists",
                "priority": "medium",
                "description": f"Extraer {len(long_lists)} listas largas",
                "method": "extract_long_lists"
            })
        
        # Estrategia por tablas grandes
        if len(large_tables) > 1:
            strategies.append({
                "type": "large_tables",
                "priority": "low",
                "description": f"Extraer {len(large_tables)} tablas grandes",
                "method": "extract_large_tables"
            })
        
        return strategies
    
    def split_by_sections(self, analysis):
        """Divide el archivo por secciones"""
        file_path = analysis["file_path"]
        sections = analysis["sections"]
        
        # Crear directorio para archivos divididos
        base_name = Path(file_path).stem
        split_dir = Path(file_path).parent / f"{base_name}_split"
        split_dir.mkdir(exist_ok=True)
        
        created_files = []
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            lines = content.split('\n')
            
            # Agrupar secciones en archivos mÃ¡s pequeÃ±os
            current_file_sections = []
            current_size = 0
            file_index = 1
            
            for section in sections:
                # Si agregar esta secciÃ³n excede el tamaÃ±o mÃ¡ximo
                if current_size + section["size"] > self.max_size and current_file_sections:
                    # Crear archivo con las secciones actuales
                    filename = f"{file_index:02d}_{self.generate_filename(current_file_sections[0]['title'])}"
                    file_path_new = split_dir / filename
                    
                    self.create_split_file(file_path_new, current_file_sections, lines)
                    created_files.append({
                        "filename": filename,
                        "path": str(file_path_new),
                        "sections": len(current_file_sections),
                        "size": current_size
                    })
                    
                    # Reiniciar para nuevo archivo
                    current_file_sections = [section]
                    current_size = section["size"]
                    file_index += 1
                else:
                    current_file_sections.append(section)
                    current_size += section["size"]
            
            # Crear Ãºltimo archivo
            if current_file_sections:
                filename = f"{file_index:02d}_{self.generate_filename(current_file_sections[0]['title'])}"
                file_path_new = split_dir / filename
                
                self.create_split_file(file_path_new, current_file_sections, lines)
                created_files.append({
                    "filename": filename,
                    "path": str(file_path_new),
                    "sections": len(current_file_sections),
                    "size": current_size
                })
            
            # Crear archivo Ã­ndice
            self.create_index_file(split_dir, created_files, analysis)
            
        except Exception as e:
            print(f"Error dividiendo archivo: {e}")
            return []
        
        return created_files
    
    def create_split_file(self, file_path, sections, all_lines):
        """Crea un archivo dividido con las secciones especificadas"""
        content_parts = []
        
        # Agregar metadatos
        metadata = f"""---
title: "{sections[0]['title']}"
source_file: "{Path(file_path).parent.parent.name}/{Path(file_path).parent.parent.name}.md"
created: "{datetime.now().isoformat()}"
sections: {len(sections)}
---
"""
        content_parts.append(metadata)
        content_parts.append("")
        
        # Agregar contenido de las secciones
        for section in sections:
            start_line = section["start_line"]
            end_line = section["end_line"]
            section_content = '\n'.join(all_lines[start_line:end_line+1])
            content_parts.append(section_content)
            content_parts.append("")
        
        # Escribir archivo
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write('\n'.join(content_parts))
    
    def create_index_file(self, split_dir, created_files, analysis):
        """Crea un archivo Ã­ndice para los archivos divididos"""
        index_content = f"""# ğŸ“ Ãndice de Archivos Divididos

**Archivo original:** {Path(analysis['file_path']).name}  
**Fecha de divisiÃ³n:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}  
**Total archivos creados:** {len(created_files)}  
**TamaÃ±o original:** {analysis['total_size']:,} caracteres  

## ğŸ“„ Archivos Creados

"""
        
        for i, file_info in enumerate(created_files, 1):
            index_content += f"{i}. **{file_info['filename']}**\n"
            index_content += f"   - Secciones: {file_info['sections']}\n"
            index_content += f"   - TamaÃ±o: {file_info['size']:,} caracteres\n"
            index_content += f"   - Ruta: `{file_info['path']}`\n\n"
        
        index_content += """
## ğŸ”— NavegaciÃ³n

- [Volver al archivo original](../{original_file})
- [Ver todos los archivos divididos](./)

## ğŸ“Š EstadÃ­sticas

- **ReducciÃ³n de tamaÃ±o promedio:** {reduction_percentage:.1f}%
- **Archivos mÃ¡s pequeÃ±os:** Mejor navegaciÃ³n y bÃºsqueda
- **OrganizaciÃ³n mejorada:** Contenido estructurado por secciones
"""
        
        # Reemplazar placeholders
        original_file = Path(analysis['file_path']).name
        total_original_size = analysis['total_size']
        total_new_size = sum(f['size'] for f in created_files)
        reduction_percentage = ((total_original_size - total_new_size) / total_original_size) * 100
        
        index_content = index_content.replace('{original_file}', original_file)
        index_content = index_content.replace('{reduction_percentage}', str(reduction_percentage))
        
        # Escribir archivo Ã­ndice
        index_path = split_dir / "README.md"
        with open(index_path, 'w', encoding='utf-8') as f:
            f.write(index_content)
    
    def generate_filename(self, title):
        """Genera un nombre de archivo basado en el tÃ­tulo"""
        # Limpiar tÃ­tulo
        filename = re.sub(r'[^\w\s-]', '', title)
        filename = re.sub(r'[-\s]+', '_', filename)
        filename = filename.lower()
        
        # Limitar longitud
        if len(filename) > 50:
            filename = filename[:50]
        
        return f"{filename}.md"
    
    def process_large_files(self, auto_split=False):
        """Procesa todos los archivos grandes"""
        print(f"ğŸ” Buscando archivos grandes (> {self.max_size} caracteres o > {self.max_lines} lÃ­neas)...")
        
        large_files = []
        
        # Encontrar archivos grandes
        for root, dirs, files in os.walk(self.root_path):
            for file in files:
                if file.endswith('.md'):
                    file_path = os.path.join(root, file)
                    try:
                        with open(file_path, 'r', encoding='utf-8') as f:
                            content = f.read()
                        
                        if len(content) > self.max_size or len(content.split('\n')) > self.max_lines:
                            large_files.append(file_path)
                    except:
                        continue
        
        print(f"ğŸ“„ Encontrados {len(large_files)} archivos grandes")
        
        for file_path in large_files:
            print(f"\nğŸ“Š Analizando: {os.path.basename(file_path)}")
            
            analysis = self.analyze_file_structure(file_path)
            if not analysis:
                continue
            
            self.split_results["files_processed"].append(analysis)
            self.split_results["total_original_size"] += analysis["total_size"]
            
            print(f"   ğŸ“ TamaÃ±o: {analysis['total_size']:,} caracteres")
            print(f"   ğŸ“ LÃ­neas: {analysis['total_lines']:,}")
            print(f"   ğŸ“‚ Secciones: {len(analysis['sections'])}")
            print(f"   ğŸ’» Bloques de cÃ³digo: {len(analysis['code_blocks'])}")
            print(f"   ğŸ“‹ Listas largas: {len(analysis['long_lists'])}")
            print(f"   ğŸ“Š Tablas grandes: {len(analysis['large_tables'])}")
            
            # Mostrar estrategias de divisiÃ³n
            if analysis['split_strategy']:
                print("   ğŸ”„ Estrategias de divisiÃ³n:")
                for strategy in analysis['split_strategy']:
                    print(f"      - {strategy['description']} ({strategy['priority']})")
            
            # Dividir archivo si se solicita
            if auto_split and analysis['split_strategy']:
                print(f"   ğŸ”„ Dividiendo archivo...")
                created_files = self.split_by_sections(analysis)
                self.split_results["files_created"].extend(created_files)
                
                total_new_size = sum(f['size'] for f in created_files)
                self.split_results["total_new_size"] += total_new_size
                
                print(f"   âœ… Archivo dividido en {len(created_files)} archivos")
        
        # Calcular porcentaje de reducciÃ³n
        if self.split_results["total_original_size"] > 0:
            self.split_results["reduction_percentage"] = (
                (self.split_results["total_original_size"] - self.split_results["total_new_size"]) / 
                self.split_results["total_original_size"]
            ) * 100
        
        return self.split_results
    
    def save_report(self, output_file="auto_split_report.json"):
        """Guarda el reporte de divisiÃ³n"""
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(self.split_results, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ“Š Reporte guardado en {output_file}")
    
    def print_summary(self):
        """Imprime un resumen de la divisiÃ³n"""
        results = self.split_results
        
        print("\n" + "="*60)
        print("ğŸ“Š RESUMEN DE DIVISIÃ“N AUTOMÃTICA")
        print("="*60)
        
        print(f"ğŸ“„ Archivos procesados: {len(results['files_processed'])}")
        print(f"ğŸ“ Archivos creados: {len(results['files_created'])}")
        print(f"ğŸ’¾ TamaÃ±o original: {results['total_original_size']:,} caracteres")
        print(f"ğŸ’¾ TamaÃ±o nuevo: {results['total_new_size']:,} caracteres")
        print(f"ğŸ“‰ ReducciÃ³n: {results['reduction_percentage']:.1f}%")
        
        if results['files_created']:
            print("\nğŸ“ Archivos creados:")
            for file_info in results['files_created']:
                print(f"  - {file_info['filename']}: {file_info['sections']} secciones, {file_info['size']:,} caracteres")

def main():
    parser = argparse.ArgumentParser(description='DivisiÃ³n automÃ¡tica de archivos grandes')
    parser.add_argument('--path', default='.', help='Ruta del directorio a analizar')
    parser.add_argument('--max-size', type=int, default=50000, help='TamaÃ±o mÃ¡ximo en caracteres')
    parser.add_argument('--max-lines', type=int, default=2000, help='NÃºmero mÃ¡ximo de lÃ­neas')
    parser.add_argument('--split', action='store_true', help='Dividir archivos automÃ¡ticamente')
    parser.add_argument('--output', default='auto_split_report.json', help='Archivo de reporte')
    
    args = parser.parse_args()
    
    splitter = AutoSplitLargeFiles(args.path, args.max_size, args.max_lines)
    results = splitter.process_large_files(args.split)
    
    splitter.save_report(args.output)
    splitter.print_summary()

if __name__ == "__main__":
    main()













